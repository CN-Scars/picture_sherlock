"""
å›¾åƒç›¸ä¼¼åº¦æœç´¢åº”ç”¨
ä¸»åº”ç”¨ç¨‹åºå…¥å£ï¼Œä½¿ç”¨Streamlitæ„å»ºç”¨æˆ·ç•Œé¢
"""
import os
import sys
import time
import tempfile
import shutil
import glob
import base64
from pathlib import Path
from typing import List, Dict, Tuple, Optional, Union, Any, Callable

# æ·»åŠ å¯¼å…¥æ¨¡å—çš„è·¯å¾„å¤„ç†
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
if parent_dir not in sys.path:
    sys.path.append(parent_dir)

import streamlit as st
import pandas as pd
import numpy as np
import torch  # å¯¼å…¥torchç”¨äºç¡¬ä»¶æ£€æµ‹
from PIL import Image
import plotly.express as px

# ä¼˜å…ˆä½¿ç”¨ç»å¯¹å¯¼å…¥
try:
    # å°è¯•ç»å¯¹å¯¼å…¥ï¼ˆå½“å®‰è£…ä¸ºåŒ…æˆ–æ·»åŠ åˆ°sys.pathæ—¶ï¼‰
    from picture_sherlock.utils import logger, validate_paths, CACHE_DIR
    from picture_sherlock.similarity_search import SimilaritySearch
    from picture_sherlock.feature_extractor import DEFAULT_MODEL_CONFIG
    from picture_sherlock.file_selector import folium_file_explorer
    from picture_sherlock.i18n import _, init_language, change_language, SUPPORTED_LANGUAGES
    from picture_sherlock.cache_manager import CacheManager
    from picture_sherlock.search_history_manager import SearchHistoryManager
except ImportError:
    # å°è¯•ç›´æ¥å¯¼å…¥ï¼ˆå½“åœ¨ç›®å½•å†…è¿è¡Œæ—¶ï¼‰
    from utils import logger, validate_paths, CACHE_DIR
    from similarity_search import SimilaritySearch
    from feature_extractor import DEFAULT_MODEL_CONFIG
    from file_selector import folium_file_explorer
    from i18n import _, init_language, change_language, SUPPORTED_LANGUAGES
    from cache_manager import CacheManager
    from search_history_manager import SearchHistoryManager

# æ£€æµ‹æ˜¯å¦å®‰è£…äº†streamlit-folium
try:
    import folium
    from streamlit_folium import st_folium
    STREAMLIT_FOLIUM_AVAILABLE = True
except ImportError:
    STREAMLIT_FOLIUM_AVAILABLE = False

# Hugging Faceæ¨¡å‹ç¼“å­˜ç›®å½•
HUGGINGFACE_CACHE_DIR = os.path.expanduser("~/.cache/huggingface")

# GitHubä»“åº“é“¾æ¥
GITHUB_REPO_URL = "https://github.com/yourusername/picture-sherlock"

# åˆå§‹åŒ–è¯­è¨€è®¾ç½®
init_language()

# é…ç½®é¡µé¢
st.set_page_config(
    page_title=_("app_title"),
    page_icon=_("app_icon"),
    layout="wide",
    initial_sidebar_state="expanded",
    menu_items={
        'About': _("about_content").replace("https://github.com/yourusername/picture-sherlock", GITHUB_REPO_URL)
    }
)

# å®šä¹‰åº”ç”¨æ ·å¼
st.markdown("""
<style>
    .main {
        padding: 2rem;
        max-width: 1200px;
        margin: 0 auto;
    }
    .preview-img {
        width: 100%;
        border-radius: 5px;
    }
    .result-img {
        width: 100%;
        border-radius: 5px;
        transition: all 0.3s;
    }
    .result-img:hover {
        transform: scale(1.05);
    }
    .stProgress .st-bo {
        background-color: #4CAF50;
    }
    .sidebar .stButton button {
        width: 100%;
    }
    .download-progress {
        margin-top: 1rem;
        padding: 1rem;
        background-color: #f0f2f6;
        border-radius: 0.5rem;
    }
    .model-info {
        margin-top: 0.5rem;
        font-size: 0.8rem;
        color: #555;
    }
    .folder-selector {
        display: flex;
        align-items: center;
        margin-bottom: 0.5rem;
    }
    .folder-list {
        margin-top: 0.5rem;
        padding: 0.5rem;
        background-color: #f0f2f6;
        border-radius: 0.5rem;
        max-height: 200px;
        overflow-y: auto;
    }
    .folder-item {
        padding: 0.3rem 0.5rem;
        margin-bottom: 0.3rem;
        background-color: white;
        border-radius: 0.3rem;
        display: flex;
        justify-content: space-between;
        align-items: center;
    }
    .search-button {
        margin-top: 1rem;
        margin-bottom: 1rem;
    }
    .cache-info {
        margin-top: 0.5rem;
        font-size: 0.9rem;
        color: #555;
        padding: 0.5rem;
        background-color: #f0f2f6;
        border-radius: 0.5rem;
    }
    .language-selector {
        margin-top: 1rem;
        padding: 0.5rem;
        background-color: #f0f2f6;
        border-radius: 0.5rem;
    }
</style>
""", unsafe_allow_html=True)


def load_image(image_path: str) -> Optional[Image.Image]:
    """
    åŠ è½½å›¾åƒæ–‡ä»¶

    Args:
        image_path: å›¾åƒæ–‡ä»¶è·¯å¾„

    Returns:
        Optional[Image.Image]: åŠ è½½çš„å›¾åƒå¯¹è±¡ï¼Œå¦‚æœåŠ è½½å¤±è´¥åˆ™è¿”å›None
    """
    try:
        return Image.open(image_path)
    except Exception as e:
        logger.error(f"åŠ è½½å›¾åƒå¤±è´¥: {image_path}, é”™è¯¯: {e}")
        return None


def get_file_download_link(file_path: str) -> str:
    """
    åˆ›å»ºæ–‡ä»¶ä¸‹è½½é“¾æ¥

    Args:
        file_path: æ–‡ä»¶è·¯å¾„

    Returns:
        str: HTMLæ ¼å¼çš„ä¸‹è½½é“¾æ¥
    """
    try:
        # è·å–æ–‡ä»¶å
        file_name = os.path.basename(file_path)

        # åˆ›å»ºä¸‹è½½é“¾æ¥
        return f'<a href="file:///{file_path}" target="_blank">{file_name}</a>'
    except Exception as e:
        logger.error(f"åˆ›å»ºä¸‹è½½é“¾æ¥å¤±è´¥: {file_path}, é”™è¯¯: {e}")
        return file_path


@st.cache_resource
def get_similarity_search(model_type: str, model_name: Optional[str] = None, _progress_callback: Optional[Callable] = None) -> SimilaritySearch:
    """
    è·å–ç›¸ä¼¼åº¦æœç´¢å®ä¾‹
    
    Args:
        model_type: æ¨¡å‹ç±»å‹
        model_name: æ¨¡å‹åç§°
        _progress_callback: è¿›åº¦å›è°ƒå‡½æ•°
        
    Returns:
        SimilaritySearch: ç›¸ä¼¼åº¦æœç´¢å®ä¾‹
    """
    return SimilaritySearch(
        model_type=model_type,
        model_name=model_name,
        download_progress_callback=_progress_callback
    )


def clear_index_cache() -> Tuple[bool, str]:
    """
    æ¸…é™¤ç´¢å¼•ç¼“å­˜æ–‡ä»¶
    
    Returns:
        Tuple[bool, str]: æ˜¯å¦æˆåŠŸåˆ é™¤å’Œæ¶ˆæ¯
    """
    try:
        # ä½¿ç”¨ç¼“å­˜ç®¡ç†å™¨æ¸…é™¤æ‰€æœ‰ç¼“å­˜
        cache_manager = CacheManager()
        deleted_count = cache_manager.clear_all_caches()
        
        if deleted_count == 0:
            return False, _("no_index_cache_found")
            
        return True, _("index_cache_deleted").format(count=deleted_count)
        
    except Exception as e:
        logger.error(f"æ¸…é™¤ç´¢å¼•ç¼“å­˜å‡ºé”™: {e}")
        return False, _("index_cache_delete_error").format(error=str(e))


def clear_model_cache() -> Tuple[bool, str]:
    """
    æ¸…é™¤Hugging Faceæ¨¡å‹ç¼“å­˜
    
    Returns:
        Tuple[bool, str]: æ˜¯å¦æˆåŠŸåˆ é™¤å’Œæ¶ˆæ¯
    """
    try:
        # æ£€æŸ¥Hugging Faceç¼“å­˜ç›®å½•æ˜¯å¦å­˜åœ¨
        if not os.path.exists(HUGGINGFACE_CACHE_DIR):
            return False, _("no_model_cache_found")
            
        # è·å–æ¨¡å‹ç¼“å­˜æ–‡ä»¶å¤¹å¤§å°
        total_size = 0
        for dirpath, dirnames, filenames in os.walk(HUGGINGFACE_CACHE_DIR):
            for filename in filenames:
                file_path = os.path.join(dirpath, filename)
                total_size += os.path.getsize(file_path)
        
        # è½¬æ¢ä¸ºMB
        size_mb = total_size / (1024 * 1024)
        
        # åˆ é™¤Hugging Faceç¼“å­˜ç›®å½•
        shutil.rmtree(HUGGINGFACE_CACHE_DIR)
        
        # é‡æ–°åˆ›å»ºç©ºç›®å½•
        os.makedirs(HUGGINGFACE_CACHE_DIR, exist_ok=True)
        
        return True, _("model_cache_deleted").format(size=f"{size_mb:.2f} MB")
        
    except Exception as e:
        logger.error(f"æ¸…é™¤æ¨¡å‹ç¼“å­˜å‡ºé”™: {e}")
        return False, _("model_cache_delete_error").format(error=str(e))


def get_cache_info() -> Dict[str, Any]:
    """
    è·å–ç¼“å­˜ä¿¡æ¯
    
    Returns:
        Dict[str, Any]: ç¼“å­˜ä¿¡æ¯
    """
    try:
        # ä½¿ç”¨ç¼“å­˜ç®¡ç†å™¨è·å–ç¼“å­˜ä¿¡æ¯
        cache_manager = CacheManager()
        cache_info = cache_manager.get_cache_info()
        
        # è·å–æ¨¡å‹ç¼“å­˜å¤§å°
        model_cache_size = 0
        if os.path.exists(HUGGINGFACE_CACHE_DIR):
            for dirpath, dirnames, filenames in os.walk(HUGGINGFACE_CACHE_DIR):
                for filename in filenames:
                    file_path = os.path.join(dirpath, filename)
                    model_cache_size += os.path.getsize(file_path)
        
        # æ·»åŠ æ¨¡å‹ç¼“å­˜ä¿¡æ¯
        cache_info['model_cache_size_bytes'] = model_cache_size
        cache_info['model_cache_size_mb'] = model_cache_size / (1024 * 1024)
        
        return cache_info

    except Exception as e:
        logger.error(f"è·å–ç¼“å­˜ä¿¡æ¯å‡ºé”™: {e}")
        return {
            'total_caches': 0,
            'total_size_bytes': 0,
            'total_size_mb': 0,
            'model_counts': {},
            'directory_stats': {},
            'status_counts': {},
            'model_cache_size_bytes': 0,
            'model_cache_size_mb': 0,
            'error': str(e)
        }


def delete_cache(cache_id: str) -> bool:
    """
    åˆ é™¤æŒ‡å®šçš„ç¼“å­˜
    
    Args:
        cache_id: ç¼“å­˜ID
        
    Returns:
        bool: åˆ é™¤æ˜¯å¦æˆåŠŸ
    """
    try:
        cache_manager = CacheManager()
        return cache_manager.delete_cache(cache_id)
    except Exception as e:
        logger.error(f"åˆ é™¤ç¼“å­˜å‡ºé”™: {e}")
        return False


def rebuild_cache(cache_id: str) -> bool:
    """
    é‡å»ºæŒ‡å®šçš„ç¼“å­˜
    
    Args:
        cache_id: ç¼“å­˜ID
        
    Returns:
        bool: é‡å»ºæ˜¯å¦æˆåŠŸ
    """
    try:
        # è·å–ç¼“å­˜ä¿¡æ¯
        cache_manager = CacheManager()
        caches = cache_manager.get_all_caches()
        cache_entry = next((c for c in caches if c['id'] == cache_id), None)
        
        if not cache_entry:
            return False
            
        # åˆ›å»ºæœç´¢å®ä¾‹å¹¶é‡å»ºç´¢å¼•
        model_name = cache_entry['model']
        dir_paths = cache_entry['dir']
        
        # æ›´æ–°ç¼“å­˜çŠ¶æ€
        cache_manager.update_cache_status(cache_id, 'rebuilding')
        
        # åˆ›å»ºæœç´¢å®ä¾‹
        search = SimilaritySearch(model_type=get_model_type_from_name(model_name))
        
        # é‡å»ºç´¢å¼•
        success = search.build_index(dir_paths, force_rebuild=True)
        
        # æ›´æ–°ç¼“å­˜çŠ¶æ€
        if success:
            cache_manager.update_cache_status(cache_id, 'indexed')
        else:
            cache_manager.update_cache_status(cache_id, 'failed')
            
        return success
    except Exception as e:
        logger.error(f"é‡å»ºç¼“å­˜å‡ºé”™: {e}")
        return False


def batch_delete_caches(cache_ids: List[str]) -> Tuple[int, int]:
    """
    æ‰¹é‡åˆ é™¤ç¼“å­˜
    
    Args:
        cache_ids: ç¼“å­˜IDåˆ—è¡¨
        
    Returns:
        Tuple[int, int]: (æˆåŠŸåˆ é™¤æ•°é‡, å¤±è´¥åˆ é™¤æ•°é‡)
    """
    try:
        cache_manager = CacheManager()
        return cache_manager.batch_delete_caches(cache_ids)
    except Exception as e:
        logger.error(f"æ‰¹é‡åˆ é™¤ç¼“å­˜å‡ºé”™: {e}")
        return (0, len(cache_ids))


def batch_rebuild_caches(cache_ids: List[str]) -> Tuple[int, int]:
    """
    æ‰¹é‡é‡å»ºç¼“å­˜
    
    Args:
        cache_ids: ç¼“å­˜IDåˆ—è¡¨
        
    Returns:
        Tuple[int, int]: (æˆåŠŸé‡å»ºæ•°é‡, å¤±è´¥é‡å»ºæ•°é‡)
    """
    success_count = 0
    fail_count = 0
    
    for cache_id in cache_ids:
        if rebuild_cache(cache_id):
            success_count += 1
        else:
            fail_count += 1
            
    return (success_count, fail_count)


def get_model_type_from_name(model_name: str) -> str:
    """
    æ ¹æ®æ¨¡å‹åç§°è·å–æ¨¡å‹ç±»å‹
    
    Args:
        model_name: æ¨¡å‹åç§°
        
    Returns:
        str: æ¨¡å‹ç±»å‹
    """
    if 'clip' in model_name.lower():
        return 'clip'
    elif 'resnet' in model_name.lower():
        return 'resnet'
    else:
        return 'clip'  # é»˜è®¤ä½¿ç”¨CLIP


def format_datetime(datetime_str: str) -> str:
    """
    æ ¼å¼åŒ–æ—¥æœŸæ—¶é—´å­—ç¬¦ä¸²
    
    Args:
        datetime_str: ISOæ ¼å¼çš„æ—¥æœŸæ—¶é—´å­—ç¬¦ä¸²
        
    Returns:
        str: æ ¼å¼åŒ–åçš„æ—¥æœŸæ—¶é—´å­—ç¬¦ä¸²
    """
    try:
        from datetime import datetime
        dt = datetime.fromisoformat(datetime_str)
        return dt.strftime('%Y-%m-%d %H:%M:%S')
    except:
        return datetime_str


def format_directory_path(dir_path: str) -> str:
    """
    æ ¼å¼åŒ–ç›®å½•è·¯å¾„ï¼Œæˆªæ–­é•¿è·¯å¾„
    
    Args:
        dir_path: ç›®å½•è·¯å¾„
        
    Returns:
        str: æ ¼å¼åŒ–åçš„è·¯å¾„
    """
    max_length = 30
    if len(dir_path) <= max_length:
        return dir_path
        
    # æˆªæ–­ä¸­é—´éƒ¨åˆ†
    parts = dir_path.split(os.sep)
    if len(parts) <= 2:
        return dir_path
        
    return os.path.join(parts[0], '...', parts[-1])


def show_search_history():
    """
    æ˜¾ç¤ºæœç´¢å†å²ç•Œé¢
    """
    st.header(_("search_history"))

    # åˆå§‹åŒ–æœç´¢å†å²ç®¡ç†å™¨
    try:
        history_manager = SearchHistoryManager()
    except Exception as e:
        st.error(f"Failed to initialize search history manager: {e}")
        return

    # è·å–ç­›é€‰å‚æ•°
    model_filter = st.session_state.get("history_model_filter", "all")
    date_filter = st.session_state.get("history_date_filter", None)
    favorites_only = st.session_state.get("history_favorites_only", False)
    search_term = st.session_state.get("history_search_term", "")

    # æ„å»ºç­›é€‰æ¡ä»¶
    filter_kwargs = {}
    if model_filter != "all":
        filter_kwargs["model_type"] = model_filter
    if date_filter:
        from datetime import datetime, time
        filter_kwargs["date_from"] = datetime.combine(date_filter, time.min)
        filter_kwargs["date_to"] = datetime.combine(date_filter, time.max)
    if favorites_only:
        filter_kwargs["favorites_only"] = True

    # è·å–æœç´¢å†å²è®°å½•
    records = history_manager.get_records_by_filter(**filter_kwargs)

    # å¦‚æœæœ‰æœç´¢è¯ï¼Œè¿›ä¸€æ­¥ç­›é€‰
    if search_term:
        filtered_records = []
        for record in records:
            # åœ¨æ ‡ç­¾ã€å¤‡æ³¨ä¸­æœç´¢
            search_fields = [
                " ".join(record.get("user_data", {}).get("tags", [])),
                record.get("user_data", {}).get("notes", "")
            ]
            if any(search_term.lower() in field.lower() for field in search_fields):
                filtered_records.append(record)
        records = filtered_records

    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric(_("total_searches"), len(records))
    with col2:
        favorite_count = sum(1 for r in records if r.get("user_data", {}).get("favorite", False))
        st.metric(_("favorite_count"), favorite_count)
    with col3:
        if records:
            avg_time = sum(r.get("results", {}).get("execution_time", 0) for r in records) / len(records)
            st.metric(_("average_execution_time"), f"{avg_time:.2f}s")
        else:
            st.metric(_("average_execution_time"), "0.00s")

    st.markdown("---")

    # æ˜¾ç¤ºæœç´¢å†å²è®°å½•
    if not records:
        st.info(_("no_search_history"))
        return

    # åˆ†é¡µè®¾ç½®
    records_per_page = 10
    total_pages = (len(records) + records_per_page - 1) // records_per_page

    if "history_current_page" not in st.session_state:
        st.session_state.history_current_page = 0

    # åˆ†é¡µæ§åˆ¶
    if total_pages > 1:
        col1, col2, col3, col4, col5 = st.columns([1, 1, 2, 1, 1])
        with col1:
            if st.button(_("previous_page"), disabled=st.session_state.history_current_page == 0):
                st.session_state.history_current_page -= 1
                st.rerun()
        with col2:
            st.write(f"{st.session_state.history_current_page + 1}/{total_pages}")
        with col3:
            page_input = st.number_input(
                _("go_to_page"),
                min_value=1,
                max_value=total_pages,
                value=st.session_state.history_current_page + 1,
                key="page_input"
            )
            if page_input != st.session_state.history_current_page + 1:
                st.session_state.history_current_page = page_input - 1
                st.rerun()
        with col4:
            st.write(f"{len(records)} {_('search_history_count').format(count='')}")
        with col5:
            if st.button(_("next_page"), disabled=st.session_state.history_current_page >= total_pages - 1):
                st.session_state.history_current_page += 1
                st.rerun()

    # è·å–å½“å‰é¡µçš„è®°å½•
    start_idx = st.session_state.history_current_page * records_per_page
    end_idx = start_idx + records_per_page
    page_records = records[start_idx:end_idx]

    # æ˜¾ç¤ºè®°å½•
    for i, record in enumerate(page_records):
        # ç”Ÿæˆæ›´æœ‰æ„ä¹‰çš„æ ‡é¢˜
        timestamp = record.get('timestamp', '')[:19]
        model_type = record.get('search_config', {}).get('model_type', 'unknown').upper()
        results_count = record.get('results', {}).get('count', 0)
        target_folders = record.get('search_config', {}).get('target_folders', [])
        folder_name = os.path.basename(target_folders[0]) if target_folders else _("unknown_folder")

        # æ„å»ºæ ‡é¢˜ï¼šæ—¶é—´ - æ¨¡å‹ - ç»“æœæ•° - æ–‡ä»¶å¤¹
        title = f"ğŸ” {timestamp} | {model_type} | {results_count}{_('results_count_suffix')} | {folder_name}"

        with st.expander(title):
            show_search_record_details(record, history_manager)

    # å¤„ç†å¯¹è¯æ¡†
    handle_history_dialogs(history_manager)


def show_search_record_details(record, history_manager):
    """
    æ˜¾ç¤ºæœç´¢è®°å½•è¯¦æƒ…
    """
    col1, col2 = st.columns([2, 1])

    with col1:
        # æ˜¾ç¤ºæŸ¥è¯¢å›¾åƒ
        record_id = record.get('id')
        stored_image_path = record.get('query_image', {}).get('stored_path')

        if history_manager:
            # ä¼˜å…ˆä½¿ç”¨stored_pathï¼Œå¦‚æœæ²¡æœ‰åˆ™å°è¯•é€šè¿‡record_idæŸ¥æ‰¾
            if stored_image_path:
                # å°†ç›¸å¯¹è·¯å¾„è½¬æ¢ä¸ºç»å¯¹è·¯å¾„
                if not os.path.isabs(stored_image_path):
                    query_image_path = os.path.join(history_manager.storage_dir, stored_image_path)
                else:
                    query_image_path = stored_image_path
            else:
                # æ—§è®°å½•ï¼šå°è¯•é€šè¿‡record_idæŸ¥æ‰¾
                query_image_path = history_manager.get_query_image_path(record_id)

            if query_image_path and os.path.exists(query_image_path):
                try:
                    query_image = load_image(query_image_path)
                    if query_image:
                        st.markdown(f"**{_('query_image')}:**")
                        st.image(query_image, width=200, caption=_("query_image_caption"))
                    else:
                        st.markdown(f"**{_('query_image')}:** {_('query_image_loading_failed')}")
                except Exception as e:
                    st.markdown(f"**{_('query_image')}:** {_('query_image_loading_error')} - {str(e)[:50]}")
            else:
                st.markdown(f"**{_('query_image')}:** {_('query_image_file_not_found')}")
        else:
            st.markdown(f"**{_('query_image')}:** {_('query_image_no_storage')}")

        st.markdown("---")

        # åŸºæœ¬ä¿¡æ¯
        st.markdown(f"**{_('search_time')}:** {record.get('timestamp', '')[:19]}")
        st.markdown(f"**{_('model_used')}:** {record.get('search_config', {}).get('model_name', 'Unknown')}")
        st.markdown(f"**{_('results_found')}:** {record.get('results', {}).get('count', 0)}")
        st.markdown(f"**{_('execution_time')}:** {record.get('results', {}).get('execution_time', 0):.2f}s")

        # ç›®æ ‡æ–‡ä»¶å¤¹
        folders = record.get('search_config', {}).get('target_folders', [])
        if folders:
            st.markdown(f"**{_('target_folders')}:**")
            for folder in folders:
                st.markdown(f"  â€¢ {folder}")

        # æœç´¢ç»“æœé¢„è§ˆ
        similar_images = record.get('results', {}).get('similar_images', [])
        if similar_images:
            st.markdown(f"**{_('search_results_preview', count=5)}:**")

            # æ˜¾ç¤ºå‰5ä¸ªç»“æœçš„ç¼©ç•¥å›¾
            cols = st.columns(5)
            for i, result in enumerate(similar_images[:5]):
                with cols[i]:
                    try:
                        image_path = result.get('path', '')
                        similarity = result.get('similarity', 0)

                        if os.path.exists(image_path):
                            image = load_image(image_path)
                            if image:
                                st.image(
                                    image,
                                    caption=f"{similarity:.3f}",
                                    use_container_width=True
                                )
                            else:
                                st.text(f"{_('cannot_load_image')}\n{os.path.basename(image_path)}")
                        else:
                            st.text(f"{_('file_not_exists')}\n{os.path.basename(image_path)}")
                    except Exception as e:
                        st.text(f"{_('error_short')}\n{str(e)[:20]}")

            # æ˜¾ç¤ºå®Œæ•´ç»“æœåˆ—è¡¨
            if len(similar_images) > 5:
                st.markdown("---")
                if st.button(f"ğŸ“‹ {_('view_all_results', count=len(similar_images))}", key=f"show_all_{record.get('id', 'unknown')}"):
                    st.session_state[f"show_all_results_{record.get('id', 'unknown')}"] = True

                if st.session_state.get(f"show_all_results_{record.get('id', 'unknown')}", False):
                    st.markdown(f"**{_('complete_results_list', count=len(similar_images))}:**")
                    for i, result in enumerate(similar_images):
                        image_path = result.get('path', '')
                        similarity = result.get('similarity', 0)
                        st.markdown(f"{i+1}. **{os.path.basename(image_path)}** - {_('similarity_label')}: {similarity:.4f}")
                        st.markdown(f"   {_('path_label')}: `{image_path}`")

                    if st.button(f"ğŸ”¼ {_('collapse_results')}", key=f"hide_all_{record.get('id', 'unknown')}"):
                        st.session_state[f"show_all_results_{record.get('id', 'unknown')}"] = False
                        st.rerun()
        else:
            st.markdown(f"**{_('search_results_no_data')}**")

    with col2:
        # æ“ä½œæŒ‰é’®
        record_id = record.get('id')
        is_favorite = record.get('user_data', {}).get('favorite', False)

        # æ”¶è—/å–æ¶ˆæ”¶è—
        if st.button(
            _("remove_from_favorites") if is_favorite else _("add_to_favorites"),
            key=f"fav_{record_id}"
        ):
            history_manager.update_record(record_id, favorite=not is_favorite)
            st.rerun()

        # é‡æ–°æ‰§è¡Œæœç´¢ï¼ˆè·³è½¬åˆ°æœç´¢é¡µé¢æ‰§è¡Œï¼‰
        if st.button(_("repeat_search"), key=f"repeat_{record_id}"):
            # è·å–å†å²è®°å½•ä¸­çš„æœç´¢å‚æ•°
            target_folders = record.get('search_config', {}).get('target_folders', [])
            model_name = record.get('search_config', {}).get('model_name', '')
            model_type = record.get('search_config', {}).get('model_type', '')
            stored_image_path = record.get('query_image', {}).get('stored_path', '')
            max_results = record.get('search_config', {}).get('max_results', 10)

            # å°†ç›¸å¯¹è·¯å¾„è½¬æ¢ä¸ºç»å¯¹è·¯å¾„
            if stored_image_path:
                # å¦‚æœæ˜¯ç›¸å¯¹è·¯å¾„ï¼Œéœ€è¦åŸºäºå†å²ç®¡ç†å™¨çš„å­˜å‚¨ç›®å½•æ„å»ºå®Œæ•´è·¯å¾„
                if not os.path.isabs(stored_image_path):
                    full_image_path = os.path.join(history_manager.storage_dir, stored_image_path)
                else:
                    full_image_path = stored_image_path
            else:
                full_image_path = ''

            # æ£€æŸ¥å¿…è¦çš„æ•°æ®æ˜¯å¦å®Œæ•´
            missing_data = []
            if not target_folders:
                missing_data.append(_("target_folders"))
            if not model_name:
                missing_data.append(_("model_name"))
            if not model_type:
                missing_data.append(_("model_type"))
            if not full_image_path or not os.path.exists(full_image_path):
                missing_data.append(_("query_image"))

            if missing_data:
                st.error(_("missing_search_data").format(data=", ".join(missing_data)))
                return

            # è®¾ç½®æœç´¢å‚æ•°å¹¶è·³è½¬åˆ°æœç´¢é¡µé¢
            st.session_state.selected_folders = target_folders
            st.session_state.repeat_search_model_name = model_name
            st.session_state.repeat_search_model_type = model_type
            st.session_state.repeat_search_image_path = full_image_path
            st.session_state.repeat_search_max_results = max_results
            st.session_state.repeat_search_stored_path = stored_image_path  # ä¿å­˜åŸå§‹ç›¸å¯¹è·¯å¾„ç”¨äºå†å²è®°å½•
            st.session_state.switch_to_search_tab = True
            st.session_state.auto_execute_search = True  # æ ‡è®°è‡ªåŠ¨æ‰§è¡Œæœç´¢
            st.success(_("switching_to_search_tab"))
            st.rerun()

        # åˆ é™¤è®°å½•
        if st.button(_("delete_record"), key=f"del_{record_id}", type="secondary"):
            if st.session_state.get(f"confirm_delete_{record_id}", False):
                history_manager.delete_record(record_id)
                st.success("Record deleted")
                st.rerun()
            else:
                st.session_state[f"confirm_delete_{record_id}"] = True
                st.warning(_("delete_record_confirm"))

    # ç”¨æˆ·æ•°æ®ç¼–è¾‘
    st.markdown("---")
    st.markdown(f"**{_('edit_tags')} & {_('edit_notes')}**")

    current_tags = record.get('user_data', {}).get('tags', [])
    current_notes = record.get('user_data', {}).get('notes', '')

    col1, col2 = st.columns(2)
    with col1:
        new_tags_str = st.text_input(
            _("user_tags"),
            value=", ".join(current_tags),
            placeholder=_("tags_placeholder"),
            key=f"tags_{record_id}"
        )

    with col2:
        new_notes = st.text_area(
            _("user_notes"),
            value=current_notes,
            placeholder=_("notes_placeholder"),
            key=f"notes_{record_id}",
            height=100
        )

    if st.button(_("save_changes"), key=f"save_{record_id}"):
        new_tags = [tag.strip() for tag in new_tags_str.split(",") if tag.strip()]
        history_manager.update_record(
            record_id,
            tags=new_tags,
            notes=new_notes
        )
        st.success("Changes saved")
        st.rerun()


def handle_history_dialogs(history_manager):
    """
    å¤„ç†æœç´¢å†å²ç›¸å…³çš„å¯¹è¯æ¡†
    """
    # å¯¼å‡ºå¯¹è¯æ¡†
    if st.session_state.get("show_export_dialog", False):
        with st.form("export_form"):
            st.subheader(_("export_history"))
            export_path = st.text_input("Export file path", value="search_history_export.json")
            include_user_data = st.checkbox("Include user data (tags, notes)", value=True)

            col1, col2 = st.columns(2)
            with col1:
                if st.form_submit_button(_("export_history")):
                    try:
                        if history_manager.export_history(export_path, include_user_data):
                            st.success(_("export_success"))
                        else:
                            st.error(_("export_failed"))
                    except Exception as e:
                        st.error(f"{_('export_failed')}: {e}")
                    st.session_state.show_export_dialog = False
                    st.rerun()
            with col2:
                if st.form_submit_button(_("cancel_changes")):
                    st.session_state.show_export_dialog = False
                    st.rerun()

    # å¯¼å…¥å¯¹è¯æ¡†
    if st.session_state.get("show_import_dialog", False):
        with st.form("import_form"):
            st.subheader(_("import_history"))
            uploaded_file = st.file_uploader("Choose history file", type=['json'])
            merge_data = st.checkbox("Merge with existing data", value=True)

            col1, col2 = st.columns(2)
            with col1:
                if st.form_submit_button(_("import_history")):
                    if uploaded_file:
                        try:
                            # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶åˆ°ä¸´æ—¶ä½ç½®
                            import tempfile
                            with tempfile.NamedTemporaryFile(mode='w', suffix='.json', delete=False) as tmp_file:
                                tmp_file.write(uploaded_file.getvalue().decode())
                                tmp_path = tmp_file.name

                            if history_manager.import_history(tmp_path, merge_data):
                                st.success(_("import_success"))
                            else:
                                st.error(_("import_failed"))

                            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                            os.unlink(tmp_path)
                        except Exception as e:
                            st.error(f"{_('import_failed')}: {e}")
                    else:
                        st.warning("Please select a file to import")
                    st.session_state.show_import_dialog = False
                    st.rerun()
            with col2:
                if st.form_submit_button(_("cancel_changes")):
                    st.session_state.show_import_dialog = False
                    st.rerun()

    # æ¸…ç©ºå†å²è®°å½•å¯¹è¯æ¡†
    if st.session_state.get("show_clear_history_dialog", False):
        with st.form("clear_history_form"):
            st.subheader(_("clear_all_history"))
            st.warning(_("clear_history_confirm"))

            col1, col2 = st.columns(2)
            with col1:
                if st.form_submit_button(_("clear_all_history"), type="primary"):
                    try:
                        if history_manager.clear_all_records():
                            st.success(_("history_cleared"))
                        else:
                            st.error("Failed to clear history")
                    except Exception as e:
                        st.error(f"Failed to clear history: {e}")
                    st.session_state.show_clear_history_dialog = False
                    st.rerun()
            with col2:
                if st.form_submit_button(_("cancel_changes")):
                    st.session_state.show_clear_history_dialog = False
                    st.rerun()

    # æ¸…ç†å­¤å„¿å›¾åƒå¯¹è¯æ¡†
    if st.session_state.get("show_cleanup_images_dialog", False):
        with st.form("cleanup_images_form"):
            st.subheader(f"ğŸ§¹ {_('cleanup_images_title')}")
            st.info(_("cleanup_images_description"))
            st.warning(f"âš ï¸ {_('cleanup_images_warning')}")

            col1, col2 = st.columns(2)
            with col1:
                if st.form_submit_button(_("start_cleanup"), type="primary"):
                    try:
                        cleaned_count = history_manager.cleanup_orphaned_images()
                        if cleaned_count > 0:
                            st.success(_("cleanup_success").format(count=cleaned_count))
                        else:
                            st.info(_("cleanup_no_files"))
                        st.session_state.show_cleanup_images_dialog = False
                        st.rerun()
                    except Exception as e:
                        st.error(_("cleanup_failed").format(error=str(e)))

            with col2:
                if st.form_submit_button(_("cancel")):
                    st.session_state.show_cleanup_images_dialog = False
                    st.rerun()


def show_favorites_management():
    """
    æ˜¾ç¤ºæ”¶è—ç®¡ç†ç•Œé¢
    """
    st.header(f"ğŸŒŸ {_('favorites_management')}")

    # åˆå§‹åŒ–æœç´¢å†å²ç®¡ç†å™¨
    try:
        history_manager = SearchHistoryManager()
    except Exception as e:
        st.error(f"Failed to initialize search history manager: {e}")
        return

    # è·å–ç­›é€‰å‚æ•°
    sort_by = st.session_state.get("favorites_sort_by", "newest")
    model_filter = st.session_state.get("favorites_model_filter", "all")

    # æ„å»ºç­›é€‰æ¡ä»¶
    filter_kwargs = {"favorites_only": True}
    if model_filter != "all":
        filter_kwargs["model_type"] = model_filter

    # è·å–æ”¶è—è®°å½•
    favorite_records = history_manager.get_records_by_filter(**filter_kwargs)

    # æ’åº
    if sort_by == "newest":
        favorite_records.sort(key=lambda x: x.get('timestamp', ''), reverse=True)
    elif sort_by == "oldest":
        favorite_records.sort(key=lambda x: x.get('timestamp', ''))
    elif sort_by == "most_similar":
        favorite_records.sort(key=lambda x: x.get('results', {}).get('top_similarity', 0), reverse=True)
    elif sort_by == "execution_time":
        favorite_records.sort(key=lambda x: x.get('results', {}).get('execution_time', 0))

    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric(_("favorites_total"), len(favorite_records))
    with col2:
        if favorite_records:
            avg_similarity = sum(r.get('results', {}).get('top_similarity', 0) for r in favorite_records) / len(favorite_records)
            st.metric(_("average_similarity"), f"{avg_similarity:.3f}")
    with col3:
        if favorite_records:
            avg_time = sum(r.get('results', {}).get('execution_time', 0) for r in favorite_records) / len(favorite_records)
            st.metric(_("average_execution_time"), f"{avg_time:.2f}s")

    if not favorite_records:
        st.info(f"ğŸŒŸ {_('no_favorites')}")
        return

    st.markdown("---")

    # åˆ†é¡µæ˜¾ç¤º
    items_per_page = 5
    total_pages = (len(favorite_records) + items_per_page - 1) // items_per_page

    if total_pages > 1:
        col1, col2, col3 = st.columns([1, 2, 1])
        with col2:
            current_page = st.selectbox(
                "é¡µé¢",
                range(1, total_pages + 1),
                format_func=lambda x: f"ç¬¬ {x} é¡µ / å…± {total_pages} é¡µ"
            ) - 1
    else:
        current_page = 0

    # è·å–å½“å‰é¡µçš„è®°å½•
    start_idx = current_page * items_per_page
    end_idx = min(start_idx + items_per_page, len(favorite_records))
    page_records = favorite_records[start_idx:end_idx]

    # æ˜¾ç¤ºæ”¶è—è®°å½•
    for i, record in enumerate(page_records):
        # ç”Ÿæˆæ ‡é¢˜
        timestamp = record.get('timestamp', '')[:19]
        model_type = record.get('search_config', {}).get('model_type', 'unknown').upper()
        results_count = record.get('results', {}).get('count', 0)
        top_similarity = record.get('results', {}).get('top_similarity', 0)
        target_folders = record.get('search_config', {}).get('target_folders', [])
        folder_name = os.path.basename(target_folders[0]) if target_folders else _("unknown_folder")

        # æ„å»ºæ ‡é¢˜ï¼šæ—¶é—´ - æ¨¡å‹ - ç»“æœæ•° - æœ€é«˜ç›¸ä¼¼åº¦ - æ–‡ä»¶å¤¹
        title = f"â­ {timestamp} | {model_type} | {results_count}{_('results_count_suffix')} | {top_similarity:.3f} | {folder_name}"

        with st.expander(title):
            show_search_record_details(record, history_manager)

    # å¤„ç†å¯¹è¯æ¡†
    handle_favorites_dialogs(history_manager)


def handle_favorites_dialogs(history_manager):
    """
    å¤„ç†æ”¶è—ç®¡ç†ç›¸å…³çš„å¯¹è¯æ¡†
    """
    # å–æ¶ˆå…¨éƒ¨æ”¶è—å¯¹è¯æ¡†
    if st.session_state.get("show_unfavorite_all_dialog", False):
        with st.form("unfavorite_all_form"):
            st.warning(f"âš ï¸ {_('unfavorite_all_confirm')}")
            st.markdown(_("unfavorite_all_description"))

            col1, col2 = st.columns(2)
            with col1:
                if st.form_submit_button(_("unfavorite_all"), type="primary"):
                    try:
                        # è·å–æ‰€æœ‰æ”¶è—è®°å½•
                        favorite_records = history_manager.get_records_by_filter(favorites_only=True)

                        # å–æ¶ˆæ‰€æœ‰æ”¶è—
                        for record in favorite_records:
                            history_manager.update_record(record['id'], favorite=False)

                        st.success(_("unfavorite_all_success").format(count=len(favorite_records)))
                        st.session_state.show_unfavorite_all_dialog = False
                        st.rerun()
                    except Exception as e:
                        st.error(f"{_('unfavorite_failed')}: {e}")

            with col2:
                if st.form_submit_button(_("cancel")):
                    st.session_state.show_unfavorite_all_dialog = False
                    st.rerun()


def show_tags_management():
    """
    æ˜¾ç¤ºæ ‡ç­¾ç®¡ç†ç•Œé¢
    """
    st.header(f"ğŸ·ï¸ {_('tags_management')}")

    # åˆå§‹åŒ–æœç´¢å†å²ç®¡ç†å™¨
    try:
        history_manager = SearchHistoryManager()
    except Exception as e:
        st.error(f"Failed to initialize search history manager: {e}")
        return

    # è·å–æ‰€æœ‰æ ‡ç­¾
    all_tags = history_manager.get_all_tags()

    if not all_tags:
        st.info(f"ğŸ“ {_('no_tags_yet')}")
        return

    # æ ‡ç­¾ç»Ÿè®¡æ¦‚è§ˆ
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric(_("total_tags"), len(all_tags))
    with col2:
        total_usage = sum(all_tags.values())
        st.metric(_("total_tag_usage"), total_usage)
    with col3:
        avg_usage = total_usage / len(all_tags) if all_tags else 0
        st.metric(_("average_tag_usage"), f"{avg_usage:.1f}")

    st.markdown("---")

    # æ ‡ç­¾äº‘æ˜¾ç¤º
    st.subheader(f"ğŸŒ¤ï¸ {_('tag_cloud')}")

    # åˆ›å»ºæ ‡ç­¾äº‘æ•°æ®
    tag_cloud_data = []
    max_usage = max(all_tags.values()) if all_tags else 1

    for tag, count in sorted(all_tags.items(), key=lambda x: x[1], reverse=True):
        # æ ¹æ®ä½¿ç”¨é¢‘ç‡è®¡ç®—å­—ä½“å¤§å°
        size = max(12, min(32, int(12 + (count / max_usage) * 20)))
        tag_cloud_data.append({
            "tag": tag,
            "count": count,
            "size": size
        })

    # æ˜¾ç¤ºæ ‡ç­¾äº‘ï¼ˆä½¿ç”¨è¡¨æ ¼å½¢å¼ï¼Œå› ä¸ºstreamlitæ²¡æœ‰åŸç”Ÿæ ‡ç­¾äº‘ç»„ä»¶ï¼‰
    st.markdown(f"### {_('tag_statistics')}")

    # åˆ›å»ºå¤šåˆ—å¸ƒå±€æ˜¾ç¤ºæ ‡ç­¾
    cols = st.columns(4)
    for i, tag_data in enumerate(tag_cloud_data):
        col_idx = i % 4
        with cols[col_idx]:
            tag = tag_data["tag"]
            count = tag_data["count"]

            # ä½¿ç”¨æŒ‰é’®æ˜¾ç¤ºæ ‡ç­¾ï¼Œç‚¹å‡»å¯ä»¥æŸ¥çœ‹ç›¸å…³è®°å½•
            if st.button(f"ğŸ·ï¸ {tag} ({count})", key=f"tag_button_{tag}"):
                st.session_state.selected_tag_for_view = tag
                st.rerun()

    st.markdown("---")

    # æ ‡ç­¾è¯¦ç»†ç»Ÿè®¡è¡¨æ ¼
    st.subheader(f"ğŸ“Š {_('tag_detailed_stats')}")

    # åˆ›å»ºDataFrame
    df = pd.DataFrame([
        {_("tag_name"): tag, _("tag_usage_count"): count, _("tag_usage_rate"): f"{count/total_usage*100:.1f}%"}
        for tag, count in sorted(all_tags.items(), key=lambda x: x[1], reverse=True)
    ])

    st.dataframe(df, hide_index=True, use_container_width=True)

    # å¦‚æœé€‰æ‹©äº†æ ‡ç­¾ï¼Œæ˜¾ç¤ºç›¸å…³è®°å½•
    if st.session_state.get("selected_tag_for_view"):
        selected_tag = st.session_state.selected_tag_for_view
        st.markdown("---")
        st.subheader(f"ğŸ” {_('tag_related_records', tag=selected_tag)}")

        # è·å–è¯¥æ ‡ç­¾çš„æ‰€æœ‰è®°å½•
        tagged_records = history_manager.get_records_by_tag(selected_tag)

        if tagged_records:
            st.info(_('tag_records_found', count=len(tagged_records), tag=selected_tag))

            # æ˜¾ç¤ºè®°å½•
            for i, record in enumerate(tagged_records[:10]):  # åªæ˜¾ç¤ºå‰10æ¡
                timestamp = record.get('timestamp', '')[:19]
                model_type = record.get('search_config', {}).get('model_type', 'unknown').upper()
                results_count = record.get('results', {}).get('count', 0)

                title = f"ğŸ” {timestamp} | {model_type} | {results_count} {_('results_count_suffix')}"

                with st.expander(title):
                    show_search_record_details(record, history_manager)

            if len(tagged_records) > 10:
                st.info(_('more_records_hidden', count=len(tagged_records) - 10))
        else:
            st.warning(_('tag_no_records', tag=selected_tag))

        # æ¸…é™¤é€‰æ‹©æŒ‰é’®
        if st.button(f"ğŸ”™ {_('back_to_tag_list')}"):
            st.session_state.selected_tag_for_view = None
            st.rerun()


def show_cache_management():
    """
    æ˜¾ç¤ºç¼“å­˜ç®¡ç†ç•Œé¢
    """
    st.header(_("cache_management_title"))
    
    # åˆå§‹åŒ–ç¼“å­˜ç®¡ç†å™¨
    cache_manager = CacheManager()
    
    # è·å–ç¼“å­˜ä¿¡æ¯
    cache_info = get_cache_info()
    
    # æ˜¾ç¤ºç¼“å­˜ç»Ÿè®¡ä¿¡æ¯
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader(_("index_cache_info"))
        st.info(_(
            "index_cache_stats").format(
            count=cache_info['total_caches'],
            size=f"{cache_info['total_size_mb']:.2f} MB"
        ))
        
        # æ˜¾ç¤ºæ¸…é™¤ç´¢å¼•ç¼“å­˜æŒ‰é’®
        if st.button(_("clear_index_cache_button"), key="clear_index_cache"):
            success, message = clear_index_cache()
            if success:
                st.success(message)
            else:
                st.warning(message)
                
    with col2:
        st.subheader(_("model_cache_info"))
        st.info(_(
            "model_cache_stats").format(
            size=f"{cache_info.get('model_cache_size_mb', 0):.2f} MB"
        ))
        
        # æ˜¾ç¤ºæ¸…é™¤æ¨¡å‹ç¼“å­˜æŒ‰é’®
        if st.button(_("clear_model_cache_button"), key="clear_model_cache"):
            success, message = clear_model_cache()
            if success:
                st.success(message)
            else:
                st.warning(message)
    
    # æ˜¾ç¤ºæ¨¡å‹ä½¿ç”¨ç»Ÿè®¡
    if cache_info['model_counts']:
        st.subheader(_("model_usage_stats"))
        
        # å‡†å¤‡å›¾è¡¨æ•°æ®
        models = list(cache_info['model_counts'].keys())
        counts = list(cache_info['model_counts'].values())
        
        # åˆ›å»ºæ¡å½¢å›¾
        fig = px.bar(
            x=models, 
            y=counts,
            labels={'x': _("model_name"), 'y': _("cache_count")},
            title=_("model_usage_chart_title")
        )
        st.plotly_chart(fig, use_container_width=True)
    
    # æ˜¾ç¤ºç¼“å­˜åˆ—è¡¨
    st.subheader(_("cache_list_title"))
    
    # åˆå§‹åŒ–ä¼šè¯çŠ¶æ€å˜é‡
    if 'selected_caches' not in st.session_state:
        st.session_state.selected_caches = []
    if 'search_keyword' not in st.session_state:
        st.session_state.search_keyword = ""
    if 'current_page' not in st.session_state:
        st.session_state.current_page = 0
    
    # æœç´¢æ¡†
    search_keyword = st.text_input(_("search_cache_placeholder"), value=st.session_state.search_keyword, key="cache_search_input")
    if search_keyword != st.session_state.search_keyword:
        st.session_state.search_keyword = search_keyword
        st.session_state.current_page = 0
    
    # è·å–ç¼“å­˜åˆ—è¡¨
    caches = cache_manager.search_caches(search_keyword)
    
    # æ‰¹é‡æ“ä½œæŒ‰é’®
    col1, col2 = st.columns(2)
    with col1:
        if st.button(_("batch_rebuild_button"), key="batch_rebuild", disabled=len(st.session_state.selected_caches) == 0):
            success_count, fail_count = batch_rebuild_caches(st.session_state.selected_caches)
            st.success(_("batch_rebuild_result").format(success=success_count, fail=fail_count))
            st.session_state.selected_caches = []
            st.experimental_rerun()
    
    with col2:
        if st.button(_("batch_delete_button"), key="batch_delete", disabled=len(st.session_state.selected_caches) == 0):
            success_count, fail_count = batch_delete_caches(st.session_state.selected_caches)
            st.success(_("batch_delete_result").format(success=success_count, fail=fail_count))
            st.session_state.selected_caches = []
            st.experimental_rerun()

    # åˆ†é¡µ
    items_per_page = 10
    total_pages = (len(caches) - 1) // items_per_page + 1 if caches else 0
    
    if total_pages > 0:
        page_start = st.session_state.current_page * items_per_page
        page_end = min(page_start + items_per_page, len(caches))
        
        # æ˜¾ç¤ºé¡µç ä¿¡æ¯
        st.text(_("pagination_info").format(
            start=page_start + 1,
            end=page_end,
            total=len(caches),
            page=st.session_state.current_page + 1,
            total_pages=total_pages
        ))
        
        # åˆ†é¡µå¯¼èˆª
        col1, col2, col3 = st.columns([1, 3, 1])
        with col1:
            if st.button("â—€", disabled=st.session_state.current_page == 0):
                st.session_state.current_page -= 1
                st.experimental_rerun()
        
        with col3:
            if st.button("â–¶", disabled=st.session_state.current_page >= total_pages - 1):
                st.session_state.current_page += 1
                st.experimental_rerun()
        
        # æ˜¾ç¤ºå½“å‰é¡µçš„ç¼“å­˜
        current_page_caches = caches[page_start:page_end]
        
        # åˆ›å»ºç¼“å­˜è¡¨æ ¼
        for cache in current_page_caches:
            cache_id = cache['id']
            model_name = cache['model']
            dirs = cache['dir'] if isinstance(cache['dir'], list) else [cache['dir']]
            created_at = format_datetime(cache['created_at'])
            updated_at = format_datetime(cache.get('updated_at', cache['created_at']))
            status = cache.get('status', 'created')
            
            # è®¡ç®—ç¼“å­˜å¤§å°
            cache_size = cache_manager.get_cache_size(cache_id)
            size_mb = cache_size / (1024 * 1024)
            
            # åˆ›å»ºç¼“å­˜é¡¹å®¹å™¨
            with st.container():
                col1, col2, col3, col4 = st.columns([0.5, 3, 1, 1])
                
                # é€‰æ‹©æ¡†
                with col1:
                    is_selected = cache_id in st.session_state.selected_caches
                    if st.checkbox("", value=is_selected, key=f"select_{cache_id}"):
                        if cache_id not in st.session_state.selected_caches:
                            st.session_state.selected_caches.append(cache_id)
                    else:
                        if cache_id in st.session_state.selected_caches:
                            st.session_state.selected_caches.remove(cache_id)
                
                # ç¼“å­˜ä¿¡æ¯
                with col2:
                    st.markdown(f"**{model_name}** ({cache_id[:8]}...)")
                    st.text(f"{_('cache_dirs')}: {', '.join([format_directory_path(d) for d in dirs])}")
                    st.text(f"{_('cache_created')}: {created_at}")
                    st.text(f"{_('cache_updated')}: {updated_at}")
                    st.text(f"{_('cache_status')}: {status}")
                    st.text(f"{_('cache_size')}: {size_mb:.2f} MB")
                
                # é‡å»ºæŒ‰é’®
                with col3:
                    if st.button(_("rebuild_button"), key=f"rebuild_{cache_id}"):
                        with st.spinner(_("rebuilding_cache")):
                            if rebuild_cache(cache_id):
                                st.success(_("rebuild_success"))
                            else:
                                st.error(_("rebuild_failed"))
                            st.experimental_rerun()
                
                # åˆ é™¤æŒ‰é’®
                with col4:
                    if st.button(_("delete_button"), key=f"delete_{cache_id}"):
                        if delete_cache(cache_id):
                            st.success(_("delete_success"))
                            if cache_id in st.session_state.selected_caches:
                                st.session_state.selected_caches.remove(cache_id)
                            st.experimental_rerun()
                        else:
                            st.error(_("delete_failed"))
                
                st.markdown("---")
    else:
        st.info(_("no_cache_found"))


def main():
    """ä¸»åº”ç”¨ç¨‹åºå…¥å£"""
    
    # ä¼šè¯çŠ¶æ€åˆå§‹åŒ–
    if 'model_download_progress' not in st.session_state:
        st.session_state.model_download_progress = 0.0
        
    if 'model_download_message' not in st.session_state:
        st.session_state.model_download_message = ""
        
    if 'is_model_ready' not in st.session_state:
        st.session_state.is_model_ready = False
        
    if 'selected_folders' not in st.session_state:
        st.session_state.selected_folders = []

    if 'show_file_explorer' not in st.session_state:
        st.session_state.show_file_explorer = False
        
    if 'search_triggered' not in st.session_state:
        st.session_state.search_triggered = False
        
    if 'last_model_type' not in st.session_state:
        st.session_state.last_model_type = ""
        
    if 'last_model_name' not in st.session_state:
        st.session_state.last_model_name = ""
        
    if 'last_force_rebuild' not in st.session_state:
        st.session_state.last_force_rebuild = False
        
    # ç¼“å­˜ç®¡ç†ç›¸å…³çŠ¶æ€
    if 'selected_tab' not in st.session_state:
        st.session_state.selected_tab = "search"  # é»˜è®¤æ˜¾ç¤ºæœç´¢é¡µé¢

    # å¤„ç†ä»å†å²è®°å½•é‡æ–°æ‰§è¡Œæœç´¢çš„æ ‡ç­¾é¡µåˆ‡æ¢
    if st.session_state.get('switch_to_search_tab', False):
        st.session_state.selected_tab = "search"
        st.session_state.switch_to_search_tab = False
        # å¦‚æœæœ‰ä¿å­˜çš„æ¨¡å‹ç±»å‹ï¼Œä¹Ÿè®¾ç½®å®ƒ
        if 'repeat_search_model_type' in st.session_state:
            st.session_state.last_model_type = st.session_state.repeat_search_model_type
    
    if 'selected_caches' not in st.session_state:
        st.session_state.selected_caches = []
        
    if 'search_keyword' not in st.session_state:
        st.session_state.search_keyword = ""
        
    if 'current_page' not in st.session_state:
        st.session_state.current_page = 0
        
    # ä¸‹è½½è¿›åº¦å›è°ƒå‡½æ•°
    def update_download_progress(message: str, progress: float):
        st.session_state.model_download_message = message
        st.session_state.model_download_progress = progress
        if progress >= 1.0:
            st.session_state.is_model_ready = True
    
    # ä¾§è¾¹æ ï¼šåº”ç”¨è®¾ç½®
    with st.sidebar:
        st.title(f"{_('app_icon')} {_('app_title')}")
        st.markdown("---")
        
        # è¯­è¨€é€‰æ‹©
        st.subheader(_("language_settings"))
        lang_cols = st.columns(len(SUPPORTED_LANGUAGES))
        
        for i, (lang_code, lang_name) in enumerate(SUPPORTED_LANGUAGES.items()):
            with lang_cols[i]:
                # å¦‚æœæ˜¯å½“å‰è¯­è¨€ï¼Œæ˜¾ç¤ºä¸ºé€‰ä¸­çŠ¶æ€
                if st.button(
                    _("chinese" if lang_code == "zh" else "english"),
                    disabled=st.session_state.language == lang_code,
                    key=f"lang_{lang_code}"
                ):
                    change_language(lang_code)
                    st.rerun()
        
        st.markdown("---")
        
        # æ ‡ç­¾é€‰æ‹©
        tab_options = ["search", "search_history", "favorites", "tags", "cache_management"]
        selected_tab = st.radio(
            _("tab_select"),
            tab_options,
            format_func=lambda x: (
                _("search_tab") if x == "search" else
                (_("search_history_tab") if x == "search_history" else
                 (_("favorites_tab") if x == "favorites" else
                  (_("tags_tab") if x == "tags" else _("cache_tab"))))
            ),
            key="selected_tab",
            index=tab_options.index(st.session_state.selected_tab)
        )
        
        st.markdown("---")
        
        # æ ¹æ®é€‰æ‹©çš„æ ‡ç­¾æ˜¾ç¤ºä¸åŒçš„ä¾§è¾¹æ å†…å®¹
        if st.session_state.selected_tab == "search":
            # æ¨¡å‹é€‰æ‹©
            st.subheader(_("model_settings"))
            
            # æ¨¡å‹ç±»å‹é€‰æ‹©
            model_type_options = [_("model_clip"), _("model_resnet"), _("model_custom")]
            model_type_selection = st.radio(
                _("select_model_type"),
                model_type_options,
                index=0,
                help=_("model_help")
            )
            
            # æ˜ å°„UIé€‰æ‹©åˆ°ä»£ç ä¸­çš„æ¨¡å‹ç±»å‹
            model_type_map = {
                _("model_clip"): "clip",
                _("model_resnet"): "resnet",
                _("model_custom"): "custom"
            }
            model_type = model_type_map.get(model_type_selection, "clip")
            
            # è‡ªå®šä¹‰æ¨¡å‹åç§°è¾“å…¥
            model_name = None
            if model_type == "custom":
                model_name = st.text_input(
                    _("model_custom"), 
                    placeholder=_("custom_model_placeholder"),
                    help=_("custom_model_help")
                )
                if not model_name:
                    st.warning(_("custom_model_required"))
            else:
                # æ˜¾ç¤ºé»˜è®¤æ¨¡å‹ä¿¡æ¯
                default_model = DEFAULT_MODEL_CONFIG.get(model_type, {}).get('name', _("unknown"))
                st.markdown(f"<div class='model-info'>{_('using_model', model_name=default_model)}</div>", unsafe_allow_html=True)
            
            # æ£€æŸ¥æ¨¡å‹æˆ–é…ç½®æ˜¯å¦å·²æ›´æ”¹ï¼Œå¦‚æœæ˜¯ï¼Œåˆ™é‡ç½®æœç´¢çŠ¶æ€
            if (st.session_state.last_model_type != model_type or 
                st.session_state.last_model_name != (model_name or "")):
                st.session_state.search_triggered = False
                st.session_state.last_model_type = model_type
                st.session_state.last_model_name = model_name or ""
                
            # æ˜¾ç¤ºæ¨¡å‹ä¸‹è½½/åŠ è½½è¿›åº¦
            if st.session_state.model_download_message:
                st.markdown(f"### {_('model_loading')}")
                st.markdown(f"<div class='download-progress'>{st.session_state.model_download_message}</div>", unsafe_allow_html=True)
                if st.session_state.model_download_progress > 0:
                    st.progress(st.session_state.model_download_progress)
                    
            # æ¨¡å‹é‡ç½®æŒ‰é’®
            if st.session_state.is_model_ready:
                if st.button(_("reset_model"), help=_("reset_model_help")):
                    st.cache_resource.clear()
                    st.session_state.is_model_ready = False
                    st.session_state.model_download_progress = 0.0
                    st.session_state.model_download_message = _("model_reset_message")
                    st.session_state.search_triggered = False  # é‡ç½®æ¨¡å‹æ—¶åŒæ—¶é‡ç½®æœç´¢çŠ¶æ€
                    st.rerun()
            
            # æœç´¢è®¾ç½®
            st.subheader(_("search_settings"))

            # æ£€æŸ¥æ˜¯å¦æ˜¯è‡ªåŠ¨æ‰§è¡Œæœç´¢ï¼Œå¦‚æœæ˜¯åˆ™ä½¿ç”¨ä¿å­˜çš„ç»“æœæ•°é‡
            auto_execute = st.session_state.get('auto_execute_search', False)
            if auto_execute and 'repeat_search_max_results' in st.session_state:
                # è‡ªåŠ¨æ‰§è¡Œæœç´¢æ—¶ï¼Œä½¿ç”¨ä¿å­˜çš„ç»“æœæ•°é‡ï¼Œä½†ä»æ˜¾ç¤ºæ»‘å—ï¼ˆç¦ç”¨çŠ¶æ€ï¼‰
                saved_max_results = st.session_state.repeat_search_max_results
                top_n = st.slider(
                    _("result_count"),
                    min_value=1,
                    max_value=50,
                    value=saved_max_results,
                    step=1,
                    help=_("result_count_help"),
                    disabled=True  # è‡ªåŠ¨æ‰§è¡Œæ—¶ç¦ç”¨æ»‘å—
                )
                st.info(f"ğŸ”„ ä½¿ç”¨å†å²è®°å½•ä¸­çš„ç»“æœæ•°é‡: {saved_max_results}")
            else:
                # æ­£å¸¸æƒ…å†µä¸‹çš„æ»‘å—
                top_n = st.slider(
                    _("result_count"),
                    min_value=1,
                    max_value=50,
                    value=10,
                    step=1,
                    help=_("result_count_help")
                )
            
            # è·¯å¾„è¾“å…¥
            st.subheader(_("image_library_path"))
            
            # æ£€æŸ¥streamlit-foliumæ˜¯å¦å¯ç”¨
            if not STREAMLIT_FOLIUM_AVAILABLE:
                st.error(_("streamlit_folium_error"))
            else:
                # æ˜¾ç¤º/éšè—æ–‡ä»¶èµ„æºç®¡ç†å™¨çš„æŒ‰é’®
                if st.button(_("open_file_explorer"), help=_("file_explorer_help")):
                    st.session_state.show_file_explorer = True
                    st.rerun()

            # æ˜¾ç¤ºå·²é€‰æ‹©çš„æ–‡ä»¶å¤¹åˆ—è¡¨
            if st.session_state.selected_folders:
                st.markdown(f"### {_('selected_folders')}")
                
                # åˆ›å»ºä¸€ä¸ªå®¹å™¨æ¥æ˜¾ç¤ºæ–‡ä»¶å¤¹åˆ—è¡¨
                with st.container():
                    for i, folder in enumerate(st.session_state.selected_folders):
                        col1, col2 = st.columns([4, 1])
                        with col1:
                            st.text(folder)
                        with col2:
                            if st.button(_("delete"), key=f"del_{i}"):
                                st.session_state.selected_folders.pop(i)
                                st.rerun()
            
                # åˆ›å»ºæ–‡æœ¬è¡¨ç¤ºï¼Œç”¨äºåç»­å¤„ç†
                folder_paths_text = "\n".join(st.session_state.selected_folders)
            else:
                folder_paths_text = ""
                st.info(_("select_folders"))
            
            # æ·»åŠ æ¸…é™¤æ‰€æœ‰æ–‡ä»¶å¤¹æŒ‰é’®
            if st.session_state.selected_folders:
                if st.button(_("clear_folders")):
                    st.session_state.selected_folders = []
                    st.rerun()
                    
            # æ‰‹åŠ¨è¾“å…¥è·¯å¾„ï¼ˆä½œä¸ºå¤‡é€‰æ–¹æ¡ˆï¼‰
            with st.expander(_("manual_input")):
                manual_paths = st.text_area(
                    _("manual_input_label"),
                    placeholder=_("manual_input_placeholder"),
                    height=100
                )
                
                # å¦‚æœæ‰‹åŠ¨è¾“å…¥äº†è·¯å¾„ï¼Œæ·»åŠ åˆ°é€‰æ‹©åˆ—è¡¨
                if manual_paths and st.button(_("add_manual_paths")):
                    new_paths = [p.strip() for p in manual_paths.split("\n") if p.strip()]
                    for path in new_paths:
                        if path not in st.session_state.selected_folders:
                            st.session_state.selected_folders.append(path)
                    st.rerun()

            force_rebuild = st.checkbox(
                _("force_rebuild"),
                value=False,
                help=_("force_rebuild_help")
            )
            
            # æ£€æŸ¥å¼ºåˆ¶é‡å»ºç´¢å¼•é€‰é¡¹æ˜¯å¦æ›´æ”¹
            if st.session_state.last_force_rebuild != force_rebuild:
                st.session_state.search_triggered = False
                st.session_state.last_force_rebuild = force_rebuild

        elif st.session_state.selected_tab == "search_history":
            # æœç´¢å†å²ä¾§è¾¹æ é€‰é¡¹
            st.subheader(_("search_history"))

            # å†å²è®°å½•ç­›é€‰é€‰é¡¹
            history_filter_type = st.selectbox(
                _("filter_by_model"),
                ["all", "clip", "resnet", "custom"],
                format_func=lambda x: _("all_searches") if x == "all" else x.upper(),
                key="history_model_filter"
            )

            # æ—¥æœŸç­›é€‰
            date_filter = st.date_input(
                _("filter_by_date"),
                value=None,
                key="history_date_filter"
            )

            # ä»…æ˜¾ç¤ºæ”¶è—
            favorites_only = st.checkbox(
                _("favorite_searches"),
                value=False,
                key="history_favorites_only"
            )

            # æœç´¢å†å²è®°å½•
            history_search_term = st.text_input(
                _("search_in_history"),
                placeholder=_("search_history_placeholder"),
                key="history_search_term"
            )

            # æ¸…é™¤ç­›é€‰æŒ‰é’®
            if st.button(_("clear_filters")):
                st.session_state.history_model_filter = "all"
                st.session_state.history_date_filter = None
                st.session_state.history_favorites_only = False
                st.session_state.history_search_term = ""
                st.rerun()

            # å†å²è®°å½•ç®¡ç†æŒ‰é’®
            st.markdown("---")
            col1, col2 = st.columns(2)
            with col1:
                if st.button(_("export_history")):
                    st.session_state.show_export_dialog = True
            with col2:
                if st.button(_("import_history")):
                    st.session_state.show_import_dialog = True

            # æ¸…ç©ºå†å²è®°å½•æŒ‰é’®
            if st.button(_("clear_all_history"), type="secondary"):
                st.session_state.show_clear_history_dialog = True

            # æ¸…ç†å­¤å„¿å›¾åƒæŒ‰é’®
            if st.button(f"ğŸ§¹ {_('cleanup_orphaned_images')}", help=_("cleanup_orphaned_images_help")):
                st.session_state.show_cleanup_images_dialog = True

        elif st.session_state.selected_tab == "favorites":
            # æ”¶è—ç®¡ç†ä¾§è¾¹æ é€‰é¡¹
            st.subheader(_("favorites_management"))

            # æ”¶è—ç­›é€‰é€‰é¡¹
            favorites_sort_by = st.selectbox(
                _("favorites_sort_by"),
                ["newest", "oldest", "most_similar", "execution_time"],
                format_func=lambda x: {
                    "newest": _("sort_newest"),
                    "oldest": _("sort_oldest"),
                    "most_similar": _("sort_most_similar"),
                    "execution_time": _("sort_execution_time")
                }[x],
                key="favorites_sort_by"
            )

            # æ¨¡å‹ç­›é€‰
            favorites_model_filter = st.selectbox(
                _("favorites_model_filter"),
                ["all", "clip", "resnet"],
                format_func=lambda x: _("all_models") if x == "all" else x.upper(),
                key="favorites_model_filter"
            )

            # æ”¶è—ç®¡ç†æ“ä½œ
            st.markdown("---")
            if st.button(_("unfavorite_all"), type="secondary"):
                st.session_state.show_unfavorite_all_dialog = True

        elif st.session_state.selected_tab == "tags":
            # æ ‡ç­¾ç®¡ç†ä¾§è¾¹æ é€‰é¡¹
            st.subheader(f"ğŸ·ï¸ {_('tags_management')}")

            # æ˜¾ç¤ºæ ‡ç­¾ç»Ÿè®¡æ¦‚è§ˆ
            try:
                history_manager = SearchHistoryManager()
                all_tags = history_manager.get_all_tags()

                if all_tags:
                    st.info(f"ğŸ“Š {_('tag_info_sidebar', count=len(all_tags))}")

                    # æ˜¾ç¤ºæœ€å¸¸ç”¨çš„æ ‡ç­¾
                    top_tags = sorted(all_tags.items(), key=lambda x: x[1], reverse=True)[:5]
                    st.markdown(f"**ğŸ”¥ {_('most_used_tags')}ï¼š**")
                    for tag, count in top_tags:
                        st.markdown(f"â€¢ {tag} ({count})")
                else:
                    st.info(f"ğŸ“ {_('no_tags_yet')}")
            except Exception as e:
                st.error(f"è·å–æ ‡ç­¾ä¿¡æ¯å¤±è´¥: {e}")

        else:  # ç¼“å­˜ç®¡ç†æ ‡ç­¾
            # ç¼“å­˜ç®¡ç†é€‰é¡¹
            st.subheader(_("cache_management_options"))

            # ç¼“å­˜æœç´¢
            search_keyword = st.text_input(_("search_cache_placeholder"), value=st.session_state.search_keyword, key="sidebar_cache_search")
            if search_keyword != st.session_state.search_keyword:
                st.session_state.search_keyword = search_keyword
                st.session_state.current_page = 0

            # åˆ·æ–°æŒ‰é’®
            if st.button(_("refresh_cache_button")):
                st.rerun()
                
        # ç¡¬ä»¶ä¿¡æ¯éƒ¨åˆ†
        with st.expander(_("hardware_info")):
            # æ£€æµ‹GPUå¯ç”¨æ€§
            if torch.cuda.is_available():
                gpu_name = torch.cuda.get_device_name(0)
                gpu_count = torch.cuda.device_count()
                
                st.success(_("gpu_detected").format(count=gpu_count))
                st.markdown(_("gpu_name").format(name=gpu_name))
                st.markdown(_("cuda_version").format(version=torch.version.cuda))
            else:
                st.warning(_("no_gpu_warning"))
                st.markdown(_("device_cpu"))
        
    # ä¸»åŒºåŸŸå†…å®¹ï¼šæ ¹æ®é€‰æ‹©çš„æ ‡ç­¾æ˜¾ç¤ºä¸åŒå†…å®¹
    if st.session_state.selected_tab == "search":
        # æœç´¢ç•Œé¢
        st.title(_("upload_title"))
        st.markdown(_("upload_description"))
        
        # æ˜¾ç¤ºæ–‡ä»¶èµ„æºç®¡ç†å™¨
        if st.session_state.show_file_explorer:
            st.subheader(_("file_explorer"))
            st.caption(_("browse_folders"))
            
            selected_path = folium_file_explorer()
            
            if selected_path:
                if selected_path not in st.session_state.selected_folders:
                    st.session_state.selected_folders.append(selected_path)
                st.session_state.show_file_explorer = False
                st.rerun()
                
            # æ·»åŠ è¿”å›æŒ‰é’®
            if st.button(_("return_to_main"), key="return_from_explorer"):
                st.session_state.show_file_explorer = False
                st.rerun()
        else:
            # æ£€æŸ¥æ˜¯å¦æ˜¯è‡ªåŠ¨æ‰§è¡Œæœç´¢ï¼ˆä»å†å²è®°å½•é‡æ–°æ‰§è¡Œï¼‰
            auto_execute = st.session_state.get('auto_execute_search', False)
            repeat_image_path = st.session_state.get('repeat_search_image_path', '')

            # ä¸Šä¼ å›¾ç‰‡ï¼ˆå¦‚æœä¸æ˜¯è‡ªåŠ¨æ‰§è¡Œæœç´¢ï¼‰
            if not auto_execute:
                uploaded_file = st.file_uploader(_("upload_image"), type=["jpg", "jpeg", "png", "bmp", "webp"])
            else:
                uploaded_file = None  # è‡ªåŠ¨æ‰§è¡Œæ—¶ä¸éœ€è¦ä¸Šä¼ 

            # çŠ¶æ€å’Œç»“æœå®¹å™¨
            status_container = st.empty()
            search_button_container = st.container()
            progress_bar = st.empty()
            results_container = st.container()

            # å¤„ç†æœç´¢
            if uploaded_file or auto_execute:
                if auto_execute:
                    # è‡ªåŠ¨æ‰§è¡Œæœç´¢ï¼šä½¿ç”¨å†å²è®°å½•ä¸­çš„å›¾åƒ
                    query_image_path = repeat_image_path
                    st.info(_("using_historical_image"))
                else:
                    # æ‰‹åŠ¨ä¸Šä¼ ï¼šå¤„ç†ä¸Šä¼ çš„æ–‡ä»¶
                    with tempfile.NamedTemporaryFile(delete=False, suffix=".jpg") as tmp_file:
                        tmp_file.write(uploaded_file.getvalue())
                        query_image_path = tmp_file.name

                # æ˜¾ç¤ºæŸ¥è¯¢å›¾åƒ
                query_image = load_image(query_image_path)
                
                if query_image:
                    # åœ¨ä¸Šæ–¹æ˜¾ç¤ºæŸ¥è¯¢å›¾åƒ
                    st.subheader(_("query_image"))
                    st.image(query_image, width=300)
                    
                    # æ·»åŠ æœç´¢æŒ‰é’®ï¼ˆå¦‚æœä¸æ˜¯è‡ªåŠ¨æ‰§è¡Œï¼‰
                    if not auto_execute:
                        with search_button_container:
                            if st.session_state.selected_folders:
                                if st.button(_("start_search"), type="primary", help=_("search_button_help"), key="search_button"):
                                    st.session_state.search_triggered = True
                                    st.rerun()
                            else:
                                st.warning(_("folder_required"))
                    else:
                        # è‡ªåŠ¨æ‰§è¡Œæœç´¢ï¼šç›´æ¥è§¦å‘æœç´¢
                        st.session_state.search_triggered = True

                    # åªæœ‰åœ¨è§¦å‘æœç´¢åæ‰æ‰§è¡Œæœç´¢
                    if st.session_state.search_triggered and st.session_state.selected_folders:
                        # éªŒè¯è‡ªå®šä¹‰æ¨¡å‹åç§°
                        if model_type == "custom" and not model_name:
                            status_container.error(_("custom_model_required"))
                        else:
                            # ä½¿ç”¨ä¼šè¯ä¸­å­˜å‚¨çš„æ–‡ä»¶å¤¹è·¯å¾„
                            folder_paths = st.session_state.selected_folders
                            valid_paths, invalid_paths = validate_paths(folder_paths)
                            
                            if not valid_paths:
                                status_container.error(_("all_paths_invalid"))
                            else:
                                if invalid_paths:
                                    st.warning(_("invalid_paths") + "\n- ".join(invalid_paths))
                                    
                                # æœç´¢ç›¸ä¼¼å›¾åƒ
                                with st.spinner(_("searching")):
                                    # åˆå§‹åŒ–è¿›åº¦æ¡
                                    progress = 0.0
                                    progress_bar_obj = progress_bar.progress(progress)
                                    
                                    def update_progress(p: float):
                                        nonlocal progress
                                        progress = p
                                        progress_bar_obj.progress(progress)
                                        
                                    # è·å–ç›¸ä¼¼åº¦æœç´¢å®ä¾‹
                                    search = get_similarity_search(
                                        model_type=model_type,
                                        model_name=model_name,
                                        _progress_callback=update_download_progress
                                    )
                                    
                                    # æ‰§è¡Œæœç´¢
                                    start_time = time.time()
                                    try:
                                        # æ£€æŸ¥æ˜¯å¦æ˜¯é‡æ–°æ‰§è¡Œæœç´¢ï¼ˆéœ€è¦å¤ç”¨å›¾åƒï¼‰
                                        reuse_image_path = st.session_state.get('repeat_search_stored_path', None)

                                        results = search.search_similar_images(
                                            query_image_path=query_image_path,
                                            folder_paths=valid_paths,
                                            top_n=top_n,
                                            force_rebuild_index=force_rebuild,
                                            progress_callback=update_progress,
                                            reuse_image_path=reuse_image_path
                                        )
                                        elapsed_time = time.time() - start_time
                                    except Exception as e:
                                        status_container.error(_("search_error").format(error=str(e)))
                                        results = []
                                        elapsed_time = time.time() - start_time
                                
                                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶ï¼ˆä»…å¯¹æ‰‹åŠ¨ä¸Šä¼ çš„æ–‡ä»¶ï¼‰
                                if not auto_execute:
                                    try:
                                        os.unlink(query_image_path)
                                    except Exception:
                                        pass

                                # æ¸…ç†é‡æ–°æ‰§è¡Œæœç´¢çš„çŠ¶æ€
                                if auto_execute:
                                    st.session_state.auto_execute_search = False
                                    if 'repeat_search_model_name' in st.session_state:
                                        del st.session_state.repeat_search_model_name
                                    if 'repeat_search_model_type' in st.session_state:
                                        del st.session_state.repeat_search_model_type
                                    if 'repeat_search_image_path' in st.session_state:
                                        del st.session_state.repeat_search_image_path
                                    if 'repeat_search_max_results' in st.session_state:
                                        del st.session_state.repeat_search_max_results
                                    if 'repeat_search_stored_path' in st.session_state:
                                        del st.session_state.repeat_search_stored_path
                                
                                # æ˜¾ç¤ºç»“æœ
                                if results:
                                    status_container.success(_("search_success").format(count=len(results), time=elapsed_time))
                                    
                                    with results_container:
                                        st.subheader(_("search_results"))
                                        st.markdown(_("sorted_by"))
                                        
                                        # åˆ›å»ºç»“æœè¡¨æ ¼åˆ—è¡¨
                                        result_data = []
                                        
                                        # åˆ›å»ºç½‘æ ¼å¸ƒå±€
                                        cols = st.columns(3)  # æ¯è¡Œ3åˆ—
                                        
                                        for idx, result in enumerate(results):
                                            col_idx = idx % len(cols)
                                            similarity = result["similarity"]
                                            path = result["path"]
                                            
                                            # å‡†å¤‡è¡¨æ ¼æ•°æ®
                                            result_data.append({
                                                _("table_index"): idx + 1,
                                                _("table_similarity"): f"{similarity:.4f}",
                                                _("table_filepath"): path
                                            })
                                            
                                            # åœ¨ç½‘æ ¼ä¸­æ˜¾ç¤ºå›¾åƒå’Œä¿¡æ¯
                                            with cols[col_idx]:
                                                try:
                                                    image = load_image(path)
                                                    if image:
                                                        st.image(
                                                            image,
                                                            caption=_("similarity").format(value=similarity),
                                                            use_container_width=True
                                                        )
                                                        # ä½¿ç”¨å¯ä¸‹è½½é“¾æ¥æ›¿æ¢çº¯æ–‡æœ¬è·¯å¾„
                                                        st.markdown(_("path").format(path=get_file_download_link(path)), unsafe_allow_html=True)
                                                        st.write("---")
                                                except Exception as e:
                                                    st.error(f"æ— æ³•åŠ è½½å›¾åƒ {path}: {e}")
                                                    
                                        # æ˜¾ç¤ºè¡¨æ ¼æ•°æ®
                                        st.subheader(_("results_table"))
                                        st.dataframe(pd.DataFrame(result_data), hide_index=True)
                                        
                                else:
                                    status_container.error(_("no_results"))
                                
                                # æ·»åŠ é‡ç½®æœç´¢æŒ‰é’®
                                if st.button(_("reset_search"), key="reset_search"):
                                    st.session_state.search_triggered = False
                                    st.rerun()
                else:
                    status_container.error(_("image_load_error"))
            else:
                status_container.info(_("upload_prompt"))
    elif st.session_state.selected_tab == "search_history":
        # æœç´¢å†å²ç•Œé¢
        show_search_history()
    elif st.session_state.selected_tab == "favorites":
        # æ”¶è—ç®¡ç†ç•Œé¢
        show_favorites_management()
    elif st.session_state.selected_tab == "tags":
        # æ ‡ç­¾ç®¡ç†ç•Œé¢
        show_tags_management()
    else:
        # ç¼“å­˜ç®¡ç†ç•Œé¢
        show_cache_management()


if __name__ == "__main__":
    main() 